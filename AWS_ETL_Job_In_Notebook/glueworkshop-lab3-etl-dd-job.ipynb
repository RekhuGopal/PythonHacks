{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding required libraries and extra jars to the job -   # <------- PLEASE REPLACE ${BUCKET_NAME} BELOW!!!\n",
    "\n",
    "%extra_py_files s3://${BUCKET_NAME}/library/pycountry_convert.zip\n",
    "%extra_jars s3://crawler-public/json/serde/json-serde.jar\n",
    "\n",
    "# Adding required properties to the job - # <------- PLEASE REPLACE ${BUCKET_NAME} BELOW!!!\n",
    "\n",
    "%%configure \n",
    "{\n",
    "  \"--enable-spark-ui\": \"true\",\n",
    "  \"--spark-event-logs-path\": \"s3://${BUCKET_NAME}/output/lab3/sparklog/\",\n",
    "  \"max_retries\": \"0\"         \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the basic Glue, Spark libraries \n",
    "\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "# Important further required libraries\n",
    "\n",
    "import os, sys, boto3\n",
    "from pprint import pprint\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from datetime import datetime\n",
    "\n",
    "# Starting Spark/Glue Context\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "\n",
    "# Important pycountry_convert function from the external python library (pycountry_convert.zip)\n",
    "\n",
    "from pycountry_convert import (\n",
    "    convert_country_alpha2_to_country_name,\n",
    "    convert_country_alpha2_to_continent,\n",
    "    convert_country_name_to_country_alpha2,\n",
    "    convert_country_alpha3_to_country_alpha2,\n",
    ")\n",
    "\n",
    "# Defining the function code\n",
    "\n",
    "def get_country_code2(country_name):\n",
    "    country_code2 = 'US'\n",
    "    try:\n",
    "        country_code2 = convert_country_name_to_country_alpha2(country_name)\n",
    "    except KeyError:\n",
    "        country_code2 = ''\n",
    "    return country_code2\n",
    "\n",
    "udf_get_country_code2 = udf(lambda z: get_country_code2(z), StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get parameter values\n",
    "\n",
    "s3_bucket_name = \"s3://${BUCKET_NAME}/\"                              # <------- PLEASE REPLACE ONLY THE ${BUCKET_NAME} HERE (Keep the \"s3://\" and the final \"/\" part)!!!\n",
    "region_name = '${AWS_REGION}'                                        #  <--- REPLACE THE AWS REGION\n",
    "ddb_table_name='glueworkshop-lab3'\n",
    "\n",
    "\n",
    "# Create the dynamodb with appropriate read and write capacity\n",
    "# Get service resource\n",
    "dynamodb = boto3.resource('dynamodb', region_name=region_name)\n",
    "\n",
    "table_status = dynamodb.create_table(\n",
    "    TableName=ddb_table_name,\n",
    "    KeySchema=[{'AttributeName': 'uuid','KeyType': 'HASH'}],\n",
    "    AttributeDefinitions=[{'AttributeName': 'uuid','AttributeType': 'N'}],\n",
    "    ProvisionedThroughput={'ReadCapacityUnits': 500,'WriteCapacityUnits': 5000}\n",
    "    )\n",
    "# Wait until the table exists.\n",
    "table_status.meta.client.get_waiter('table_exists').wait(TableName=ddb_table_name)\n",
    "pprint(table_status)\n",
    "\n",
    "df = spark.read.load(s3_bucket_name + \"input/lab2/sample.csv\", \n",
    "                     format=\"csv\", \n",
    "                     sep=\",\", \n",
    "                     inferSchema=\"true\", \n",
    "                     header=\"true\")\n",
    "\n",
    "\n",
    "new_df = df.withColumn('country_code_2', udf_get_country_code2(col(\"Country\")))\n",
    "new_df_dyf=DynamicFrame.fromDF(new_df, glueContext, \"new_df_dyf\")\n",
    "\n",
    "print(\"Start writing to DBB : {}\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "glueContext.write_dynamic_frame_from_options(\n",
    "    frame=new_df_dyf,\n",
    "    connection_type=\"dynamodb\",\n",
    "    connection_options={\n",
    "        \"dynamodb.output.tableName\": ddb_table_name,\n",
    "        \"dynamodb.throughput.write.percent\": \"1.0\"\n",
    "    }\n",
    ")\n",
    "print(\"Finished writing to DBB : {}\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "# Comparing Counts\n",
    "    \n",
    "new_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
